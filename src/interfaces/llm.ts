import type { Message } from '../types/common';

/**
 * Defines the essential operations for a Large Language Model (LLM).
 * This interface provides a standardized way to interact with various LLM implementations,
 * covering model lifecycle (loading, unloading) and core text generation capabilities.
 * It supports streaming of generated tokens for interactive applications.
 */
export interface LLM {
  /**
   * Loads the LLM model resources (e.g., weights, tokenizer) into memory.
   * This should be called before attempting to generate text.
   * @returns A promise that resolves to the instance of the LLM once loaded.
   */
  load: () => Promise<this>;

  /**
   * Interrupts any ongoing text generation process.
   * This can be useful for stopping long-running generations prematurely.
   */
  interrupt: () => void;

  /**
   * Unloads the LLM and its associated resources from memory.
   * This is typically used to free up system resources when the model is no longer needed.
   */
  unload: () => void;

  /**
   * Generates a text response based on a sequence of messages.
   * The callback function allows for streaming tokens as they are generated.
   * @param messages An array of message objects representing the conversation history.
   * @param callback A function that is called with each new token generated by the LLM.
   * @returns A promise that resolves to the complete generated string.
   */
  generate: (
    messages: Message[],
    callback: (token: string) => void
  ) => Promise<string>;
}
